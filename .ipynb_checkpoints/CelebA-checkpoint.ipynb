{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from model.hybrid_CNN import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 1 # WE WANT IMAGES TO PASS HYBRID CONV LAYER ONE BY ONE\n",
    "learning_rate = 0.001\n",
    "model_name = ConvNet()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "def load_data(batch_size):\n",
    "    \"\"\"\n",
    "    return the train/val/test dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='train',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "    val_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='valid',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "    test_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='test',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, learning_rate, num_classes, device):\n",
    "    \"\"\"\n",
    "    initialize the model (pretrained vgg16_bn)\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    # model = models.vgg16_bn(pretrained=True)                ############## add param here? ################\n",
    "    # num_ftrs = model.classifier[6].in_features\n",
    "    # model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    model = model_name.to(device)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(step_hist, loss_hist, epoch=0):\n",
    "    plt.plot(step_hist, loss_hist)\n",
    "    plt.xlabel('train_iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('epoch'+str(epoch+1))\n",
    "    plt.savefig('epoch_1')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory and train for specified number of epochs\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs): # repeat the entire training `num_epochs` times\n",
    "        # for each training sample\n",
    "        loss_hist = []\n",
    "        step_hist = []\n",
    "        for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "            # move to gpu if available\n",
    "            label = labels[:, 2]   # attractiveness label\n",
    "            cov_attr = labels[:, 20]    # gender (male/female)   \n",
    "            cov_attr = (cov_attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
    "            \n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "#             outputs = model(images, cov_attr)    # model takes covariate here\n",
    "            outputs = model(images)\n",
    "            print(\"outputs: \", outputs)\n",
    "            print(\"label: \", label)\n",
    "            loss = criterion(outputs, label) \n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch: [{}/{}], Step[{}/{}], Loss:{:.4f}' \\\n",
    "                    .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "                loss_hist.append(loss.item())\n",
    "                step_hist.append(i+1)\n",
    "        \n",
    "        make_plots(step_hist, loss_hist, epoch)\n",
    "        \n",
    "    torch.save(model.state_dict(), 'cnn1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 115 image shape:  torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9297522689f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-448a861da49e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_attr\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# model takes covariate here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"outputs: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train(train_loader, model, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Run the validation set on the trained model\n",
    "    \"\"\"\n",
    "    model.eval() # BatchNorm uses moving mean/variance instead of mini-batch mean/variance\n",
    "    with torch.no_grad():\n",
    "        # initialize the stats\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # pass through testing data once\n",
    "        for images, labels in val_loader:\n",
    "\n",
    "            label = labels[:, 2]\n",
    "            # again move to device first\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            # forward once\n",
    "            outputs = model(images)\n",
    "            # instead of calculating loss we will get predictions\n",
    "            # it's essetially outputs just reformatting imo\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # accumulate stats\n",
    "            total += label.size(0) # yeah again, number of elements in the tensor\n",
    "            correct += (label == predicted).sum().item()\n",
    "\n",
    "        # print\n",
    "        print('Test accuracy on 10000 test images: {}%' \\\n",
    "                .format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run validation set\n",
    "evaluate(val_loader, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (celeb_a)",
   "language": "python",
   "name": "pycharm-b8c63a84"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
