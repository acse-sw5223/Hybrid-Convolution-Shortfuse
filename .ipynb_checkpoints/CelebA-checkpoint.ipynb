{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from model.vgg16 import *\n",
    "from model.hybrid_CNN import Hybrid_Conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vgg16_bn_8_testing'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "num_epochs = 1\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "model_name = vgg16_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "def load_data(batch_size):\n",
    "    \"\"\"\n",
    "    return the train/val/test dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='train',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "    val_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='valid',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "    test_dataset = datasets.CelebA(root='./data',\n",
    "                                    split='test',\n",
    "                                    target_type='attr',\n",
    "                                    transform=transform,\n",
    "                                    download=False)\n",
    "\n",
    "    # data loader\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, learning_rate, num_classes, device):\n",
    "    \"\"\"\n",
    "    initialize the model (pretrained vgg16_bn)\n",
    "    define loss function and optimizer and move data to gpu if available\n",
    "    \n",
    "    return:\n",
    "        model, loss function(criterion), optimizer\n",
    "    \"\"\"\n",
    "    model = model_name\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    model = model_name.to(device)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "\n",
    "model, criterion, optimizer = initialize_model(model_name, learning_rate, num_classes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(step_hist, loss_hist, epoch=0):\n",
    "    plt.plot(step_hist, loss_hist)\n",
    "    plt.xlabel('train_iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('epoch'+str(epoch+1))\n",
    "    plt.savefig('epoch_1')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Move data to GPU memory and train for specified number of epochs\n",
    "    Also plot the loss function and save it in `Figures/`\n",
    "    Trained model is saved as `cnn.ckpt`\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs): # repeat the entire training `num_epochs` times\n",
    "        # for each training sample\n",
    "        loss_hist = []\n",
    "        step_hist = []\n",
    "        for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "            # move to gpu if available\n",
    "            label = labels[:, 2]   # attractiveness label\n",
    "            cov_attr = labels[:, 20]    # gender (male/female)   \n",
    "            cov_attr = (cov_attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
    "            \n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(images, cov_attr)    # model takes covariate here\n",
    "            loss = criterion(outputs, label) \n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch: [{}/{}], Step[{}/{}], Loss:{:.4f}' \\\n",
    "                    .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "                loss_hist.append(loss.item())\n",
    "                step_hist.append(i+1)\n",
    "        \n",
    "        make_plots(step_hist, loss_hist, epoch)\n",
    "        \n",
    "    torch.save(model.state_dict(), 'cnn2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train(train_loader, model, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, device):\n",
    "    \"\"\"\n",
    "    Run the validation set on the trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    model_path = \"model/vgg16_bn_32.ckpt\"\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    model.eval() # BatchNorm uses moving mean/variance instead of mini-batch mean/variance\n",
    "    with torch.no_grad():\n",
    "        # initialize the stats\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        # pass through testing data once\n",
    "        for images, labels in val_loader:\n",
    "\n",
    "            label = labels[:, 2]\n",
    "#             cov_attr = labels[:, 20]    # gender (male/female)   \n",
    "#             cov_attr = (cov_attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
    "            # again move to device first\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # forward once\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # instead of calculating loss we will get predictions\n",
    "            # it's essetially outputs just reformatting imo\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # accumulate stats\n",
    "            y_true.append(label)\n",
    "            y_pred.append(predicted)\n",
    "            total += label.size(0) # yeah again, number of elements in the tensor\n",
    "            correct += (label == predicted).sum().item()\n",
    "\n",
    "        # print\n",
    "        print('Test accuracy on validation set: {}%' \\\n",
    "                .format(100 * correct / total))\n",
    "        \n",
    "# run validation set\n",
    "evaluate(val_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/vgg16_bn_32.ckpt\"\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    # initialize the stats\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # pass through testing data once\n",
    "    for images, labels in tqdm(val_loader):\n",
    "\n",
    "        label = labels[:, 2]\n",
    "        # cov_attr = labels[:, 20]   \n",
    "        # cov_attr = (cov_attr + 1) // 2  # (32,)\n",
    "        # again move to device first\n",
    "        \n",
    "        images = images.to(device) # (1, 3, 224, 224) -> (32, 3, 224, 224)\n",
    "        label = label.to(device)   # (1,) -> (32,)\n",
    "\n",
    "        # forward once\n",
    "        outputs = model(images)\n",
    "        # outputs = model(images, cov_attr)  # forward has to take a batch\n",
    "\n",
    "        # instead of calculating loss we will get predictions\n",
    "        # it's essetially outputs just reformatting imo\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # accumulate stats\n",
    "        y_true.append(label.item())\n",
    "        y_pred.append(predicted.item())\n",
    "        total += label.size(0) # yeah again, number of elements in the tensor\n",
    "        correct += (label == predicted).sum().item()\n",
    "\n",
    "    # print\n",
    "    print('Test accuracy on validation set: {}%' \\\n",
    "            .format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.as_tensor(y_true)\n",
    "y_pred = torch.as_tensor(y_pred)\n",
    "\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 0],\n",
    "     [1, 0]]\n",
    "\n",
    "b = [[1, 1],\n",
    "     [1, 1]]\n",
    "\n",
    "f1_score(a, b, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.as_tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (celeb_a)",
   "language": "python",
   "name": "pycharm-b8c63a84"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
